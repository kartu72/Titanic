{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title=''\n",
    "    for i in name:\n",
    "        if i==' ':\n",
    "            title=''\n",
    "        elif i=='.':\n",
    "            return title\n",
    "        else:\n",
    "            title=title+i\n",
    "    return 'Without title'\n",
    "def Cabin_null_processing(name):\n",
    "    if (type(name) is int):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def Age_null_processing1(Age):\n",
    "    return 37\n",
    "def Age_null_processing2(Age):\n",
    "    return 29\n",
    "def Age_null_processing3(Age):\n",
    "    return 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "data['Embarked']=data['Embarked'].replace(np.nan, 'S')\n",
    "test_data['Embarked']=test_data['Embarked'].replace(np.nan, 'S')\n",
    "\n",
    "#Cabin\n",
    "data['Cabin']=data['Cabin'].replace(np.nan, 0)\n",
    "data['Cabin']=data['Cabin'].map(Cabin_null_processing)\n",
    "data['Cabin']=data['Cabin'].replace(np.nan, 0)\n",
    "data['Cabin']=data['Cabin'].map(Cabin_null_processing)\n",
    "test_data['Cabin']=test_data['Cabin'].replace(np.nan, 0)\n",
    "test_data['Cabin']=test_data['Cabin'].map(Cabin_null_processing)\n",
    "test_data['Cabin']=test_data['Cabin'].replace(np.nan, 0)\n",
    "test_data['Cabin']=test_data['Cabin'].map(Cabin_null_processing)\n",
    "#Age\n",
    "for i in  range(len(data)):\n",
    "    if (pd.isna(data.loc[i, 'Age'])==True):\n",
    "        if (data.loc[i,'Pclass']==1):\n",
    "            data.loc[i,'Age'] = 37\n",
    "        elif (data.loc[i,'Pclass']==2):\n",
    "            data.loc[i,'Age'] = 29\n",
    "        elif (data.loc[i,'Pclass']==3):\n",
    "            data.loc[i,'Age'] = 27\n",
    "for i in  range(len(test_data)):\n",
    "    if (pd.isna(test_data.loc[i, 'Age'])==True):\n",
    "        if (test_data.loc[i,'Pclass']==1):\n",
    "            test_data.loc[i,'Age'] = 37\n",
    "        elif (test_data.loc[i,'Pclass']==2):\n",
    "            test_data.loc[i,'Age'] = 29\n",
    "        elif (test_data.loc[i,'Pclass']==3):\n",
    "            test_data.loc[i,'Age'] = 27            \n",
    "#Fare\n",
    "test_data['Fare']=test_data['Fare'].replace(np.nan, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sex\n",
    "data.Sex=data.Sex.replace({'male': 1, 'female' : 0})\n",
    "test_data.Sex=test_data.Sex.replace({'male': 1, 'female' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticket\n",
    "data=data.drop(columns=['Ticket'])\n",
    "test_data=test_data.drop(columns=['Ticket'])\n",
    "#data['Ticket']=LabelEncoder().fit_transform(data.Ticket)\n",
    "#data1['Ticket']=LabelEncoder().fit_transform(data1.Ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New feature 'Title' & drop 'Name'\n",
    "data['Title']=data['Name'].map(get_title)\n",
    "data=data.drop(columns=['Name'])\n",
    "test_data['Title']=test_data['Name'].map(get_title)\n",
    "test_data=test_data.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "data['Embarked']=data['Embarked'].replace({'Q':1, 'C':2, 'S':3})\n",
    "test_data['Embarked']=test_data['Embarked'].replace({'Q':1, 'C':2, 'S':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PassengerId\n",
    "#data=data.drop(columns='PassengerId')\n",
    "#data1=data1.drop(columns='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title\n",
    "data['Title']=LabelEncoder().fit_transform(data.Title)\n",
    "test_data['Title']=LabelEncoder().fit_transform(test_data.Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby('Pclass')[['Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby('Sex')[['Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby('Embarked')[['Survived']].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Embarked', 'Pclass', 'Survived']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Pclass'])[['Fare']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['SibSp'])[['Fare']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['SibSp'])[['Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Parch'])[['Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Pclass'])[['Age']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[pd.isna(data['Cabin'])==False]['Survived'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby('Embarked').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby('Cabin').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Pclass'])[['Age']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Title'])[['Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['male', 'female']\n",
    "counts = data.Sex.value_counts(['male','female'])\n",
    "plt.figure(figsize=(2, 5))\n",
    "plt.ylabel('Survived')\n",
    "plt.ylim([0, 1])\n",
    "plt.bar(names, [(data.Sex.value_counts().iloc[1])/data.Sex.size,(data.Sex.value_counts().iloc[0])/data.Sex.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fare = list(data.Fare.array)\n",
    "Age = list(data.Age.array)\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Age')\n",
    "print(type(Age))\n",
    "plt.plot(Fare, Age, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parch = list(data.Parch.array)\n",
    "Quantity=[0 for i in range(7)]\n",
    "#print(Parch)\n",
    "#print(Quanitity)\n",
    "for i in np.unique(Parch):\n",
    "    Quantity[i]=np.sum(Parch==i)\n",
    "Parch=np.unique(Parch)\n",
    "plt.xlabel('Parch')\n",
    "plt.ylabel('Quantity')\n",
    "plt.bar(Parch, Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SibSp = list(data.SibSp.array)\n",
    "Quantity=[0 for i in range(7)]\n",
    "for j,i in enumerate(np.unique(SibSp)):\n",
    "    Quantity[j]=np.sum(SibSp==i)\n",
    "SibSp=np.unique(SibSp)\n",
    "print(Quantity)\n",
    "print(SibSp)\n",
    "plt.xlabel('SibSp')\n",
    "plt.ylabel('Quantity')\n",
    "plt.bar(SibSp, Quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n"
     ]
    }
   ],
   "source": [
    "train_labels=data['Survived']\n",
    "train_data=data.drop(columns='Survived')\n",
    "data = shuffle(data)\n",
    "val_n=int(0.75*len(data))\n",
    "train_data, val_data = np.split(data,[val_n])\n",
    "train_labels=train_data['Survived']\n",
    "val_labels=val_data['Survived']\n",
    "train_data=train_data.drop(columns=['Survived'])\n",
    "val_data=val_data.drop(columns=['Survived'])\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked  \\\n",
       "0            1       3    1  22.0      1      0   7.2500      0         3   \n",
       "1            2       1    0  38.0      1      0  71.2833      0         2   \n",
       "2            3       3    0  26.0      0      0   7.9250      0         3   \n",
       "3            4       1    0  35.0      1      0  53.1000      0         3   \n",
       "4            5       3    1  35.0      0      0   8.0500      0         3   \n",
       "\n",
       "   Title  \n",
       "0     12  \n",
       "1     13  \n",
       "2      9  \n",
       "3     13  \n",
       "4     12  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>781</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked  \\\n",
       "84            85       2    0  17.0      0      0  10.5000      0         3   \n",
       "869          870       3    1   4.0      1      1  11.1333      0         3   \n",
       "94            95       3    1  59.0      0      0   7.2500      0         3   \n",
       "829          830       1    0  62.0      0      0  80.0000      0         3   \n",
       "780          781       3    0  13.0      0      0   7.2292      0         2   \n",
       "\n",
       "     Title  \n",
       "84       9  \n",
       "869      8  \n",
       "94      12  \n",
       "829     13  \n",
       "780      9  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratify split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n"
     ]
    }
   ],
   "source": [
    "#rand = np.random.RandomState(10)\n",
    "#shuffle=rand.permutation(len(data))\n",
    "#train_data, val_data, train_labels, val_labels = train_test_split(data.drop(columns='Survived'), data['Survived'],test_size=0.2, random_state=1, stratify=data['Survived'])\n",
    "#print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8161434977578476\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap': True,\n",
    " 'max_depth': 90,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 500}\n",
    "model = RandomForestClassifier(**params)\n",
    "model.fit(train_data, train_labels)\n",
    "predictions_RF = model.predict(test_data)\n",
    "print('accuracy: ', accuracy_score(model.predict(val_data), val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [1000, 1200, 2000]}#, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1188 candidates, totalling 3564 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3564 out of 3564 | elapsed: 31.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "GSmodel=RandomForestClassifier()\n",
    "GridS = GridSearchCV(GSmodel,params, cv=3,verbose=2,n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)\n",
    "print('accuracy: ', accuracy_score(GridS.predict(val_data), val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8189054726368159\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap': True,\n",
    " 'max_depth': None,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 100,\n",
    "}\n",
    "mlflow.set_experiment('RF')\n",
    "with mlflow.start_run():\n",
    "    model=RandomForestClassifier(**params)\n",
    "    model.fit(train_data, train_labels)\n",
    "    accuracy = cross_val_score(model, train_data, train_labels, scoring='accuracy', cv = 10)\n",
    "    mlflow.log_param('params', params)\n",
    "    mlflow.log_metric('accuracy', accuracy.mean())\n",
    "    print(accuracy.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy on val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8340807174887892\n",
      "[1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0\n",
      " 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "params ={'bootstrap': True,\n",
    " 'max_depth': 90,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 500}\n",
    "model=RandomForestClassifier(**params)\n",
    "model.fit(train_data, train_labels)\n",
    "print('accuracy', accuracy_score(model.predict(val_data),val_labels))\n",
    "print(model.predict(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "params={'colsample_bytree': 0.8,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 9.0,\n",
    " 'subsample': 0.9}\n",
    "model = XGBClassifier(**params)\n",
    "model.fit(train_data, train_labels)\n",
    "predictions_XGB = model.predict(test_data)\n",
    "#print('accuracy: ', accuracy_score(model.predict(test_data), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search(XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {\n",
    "#        'min_child_weight': [1, 5, 10],\n",
    "#        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#        'subsample': [0.6, 0.8, 1.0],\n",
    "#        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#        'max_depth': [3, 4, 5],\n",
    "#        'n_estimators': [200,400]\n",
    "#        }\n",
    "params = {\n",
    "        'min_child_weight': np.linspace(1,10,10),\n",
    "        'subsample': np.linspace(0.5,1,6),\n",
    "        'colsample_bytree': np.linspace(0.5,1,6),\n",
    "        'max_depth': np.linspace(3,10,7).astype('int32'),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2520 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2892 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3946 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5160 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6538 tasks      | elapsed:  2.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy:  0.8268156424581006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 7560 out of 7560 | elapsed:  2.9min finished\n",
      "D:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "GSmodel=XGBClassifier()\n",
    "GridS = GridSearchCV(GSmodel,params, cv=3,verbose=2,n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)\n",
    "print('accuracy: ', accuracy_score(GridS.predict(val_data), val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 9.0,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search with mlflow (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_accuracy: 0.8024197195838987\n",
      "accuracy on val_data: 0.8116591928251121\n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': 0.8,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 9.0,\n",
    " 'subsample': 0.9}\n",
    "mlflow.set_experiment('XGB')\n",
    "with mlflow.start_run():\n",
    "    model=XGBClassifier(**params, eval_metric = 'logloss')\n",
    "    #model.fit(train_data, train_labels, eval_metric = 'logloss')\n",
    "    accuracy = cross_val_score(model, train_data, train_labels, scoring='accuracy', cv = 10)\n",
    "    mlflow.log_param('params', params)\n",
    "    mlflow.log_metric('cv_accuracy', accuracy.mean())\n",
    "    print('cv_accuracy:', accuracy.mean())\n",
    "    model=XGBClassifier(**params)\n",
    "    model.fit(train_data, train_labels,eval_metric = 'logloss')\n",
    "    print('accuracy on val_data:', accuracy_score(model.predict(val_data),val_labels))\n",
    "    mlflow.log_metric('accuracy on val_data', accuracy_score(model.predict(val_data),val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6193579\ttotal: 70.6ms\tremaining: 3.46s\n",
      "1:\tlearn: 0.5716354\ttotal: 71ms\tremaining: 1.7s\n",
      "2:\tlearn: 0.5322972\ttotal: 84ms\tremaining: 1.31s\n",
      "3:\tlearn: 0.4956877\ttotal: 84.5ms\tremaining: 972ms\n",
      "4:\tlearn: 0.4703895\ttotal: 97.2ms\tremaining: 875ms\n",
      "5:\tlearn: 0.4531190\ttotal: 110ms\tremaining: 805ms\n",
      "6:\tlearn: 0.4372028\ttotal: 123ms\tremaining: 753ms\n",
      "7:\tlearn: 0.4260892\ttotal: 135ms\tremaining: 710ms\n",
      "8:\tlearn: 0.4158603\ttotal: 147ms\tremaining: 671ms\n",
      "9:\tlearn: 0.4070430\ttotal: 160ms\tremaining: 639ms\n",
      "10:\tlearn: 0.3984556\ttotal: 166ms\tremaining: 587ms\n",
      "11:\tlearn: 0.3895414\ttotal: 171ms\tremaining: 543ms\n",
      "12:\tlearn: 0.3822631\ttotal: 184ms\tremaining: 522ms\n",
      "13:\tlearn: 0.3767112\ttotal: 184ms\tremaining: 473ms\n",
      "14:\tlearn: 0.3710761\ttotal: 196ms\tremaining: 458ms\n",
      "15:\tlearn: 0.3660758\ttotal: 208ms\tremaining: 443ms\n",
      "16:\tlearn: 0.3611474\ttotal: 211ms\tremaining: 410ms\n",
      "17:\tlearn: 0.3566061\ttotal: 224ms\tremaining: 398ms\n",
      "18:\tlearn: 0.3501018\ttotal: 236ms\tremaining: 384ms\n",
      "19:\tlearn: 0.3455477\ttotal: 248ms\tremaining: 371ms\n",
      "20:\tlearn: 0.3419246\ttotal: 261ms\tremaining: 360ms\n",
      "21:\tlearn: 0.3375927\ttotal: 274ms\tremaining: 349ms\n",
      "22:\tlearn: 0.3326181\ttotal: 287ms\tremaining: 336ms\n",
      "23:\tlearn: 0.3281311\ttotal: 299ms\tremaining: 324ms\n",
      "24:\tlearn: 0.3237611\ttotal: 311ms\tremaining: 311ms\n",
      "25:\tlearn: 0.3199935\ttotal: 323ms\tremaining: 298ms\n",
      "26:\tlearn: 0.3147806\ttotal: 335ms\tremaining: 285ms\n",
      "27:\tlearn: 0.3128074\ttotal: 336ms\tremaining: 264ms\n",
      "28:\tlearn: 0.3084856\ttotal: 348ms\tremaining: 252ms\n",
      "29:\tlearn: 0.3052992\ttotal: 359ms\tremaining: 240ms\n",
      "30:\tlearn: 0.3021481\ttotal: 371ms\tremaining: 228ms\n",
      "31:\tlearn: 0.2993754\ttotal: 385ms\tremaining: 216ms\n",
      "32:\tlearn: 0.2958266\ttotal: 397ms\tremaining: 204ms\n",
      "33:\tlearn: 0.2954373\ttotal: 422ms\tremaining: 198ms\n",
      "34:\tlearn: 0.2952614\ttotal: 424ms\tremaining: 182ms\n",
      "35:\tlearn: 0.2918246\ttotal: 437ms\tremaining: 170ms\n",
      "36:\tlearn: 0.2890201\ttotal: 450ms\tremaining: 158ms\n",
      "37:\tlearn: 0.2865163\ttotal: 464ms\tremaining: 147ms\n",
      "38:\tlearn: 0.2837950\ttotal: 477ms\tremaining: 135ms\n",
      "39:\tlearn: 0.2824875\ttotal: 490ms\tremaining: 122ms\n",
      "40:\tlearn: 0.2785790\ttotal: 502ms\tremaining: 110ms\n",
      "41:\tlearn: 0.2746440\ttotal: 515ms\tremaining: 98.1ms\n",
      "42:\tlearn: 0.2729073\ttotal: 528ms\tremaining: 85.9ms\n",
      "43:\tlearn: 0.2723417\ttotal: 539ms\tremaining: 73.6ms\n",
      "44:\tlearn: 0.2690517\ttotal: 552ms\tremaining: 61.3ms\n",
      "45:\tlearn: 0.2685524\ttotal: 565ms\tremaining: 49.1ms\n",
      "46:\tlearn: 0.2652315\ttotal: 578ms\tremaining: 36.9ms\n",
      "47:\tlearn: 0.2644066\ttotal: 591ms\tremaining: 24.6ms\n",
      "48:\tlearn: 0.2633248\ttotal: 603ms\tremaining: 12.3ms\n",
      "49:\tlearn: 0.2630888\ttotal: 617ms\tremaining: 0us\n",
      "Your submission was successfully saved!\n",
      "accuracy:  0.8071748878923767\n"
     ]
    }
   ],
   "source": [
    "params ={'depth': 10, 'iterations': 50, 'learning_rate': 0.25   }\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_data, train_labels)\n",
    "predictions_Catboost = model.predict(test_data)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "print('accuracy: ', accuracy_score(model.predict(val_data), val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid search (Catbo0st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'depth': [4,5,6,7,8,9,10],\n",
    "                  'learning_rate' : [0.05,0.1,0.2,0.25],\n",
    "                  'iterations'    : [10,20,30,40,50,60,70,80,90,100]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 280 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 804 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 840 out of 840 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6325930\ttotal: 62.3ms\tremaining: 3.05s\n",
      "1:\tlearn: 0.5788265\ttotal: 62.7ms\tremaining: 1.5s\n",
      "2:\tlearn: 0.5348055\ttotal: 76.7ms\tremaining: 1.2s\n",
      "3:\tlearn: 0.4987933\ttotal: 77.6ms\tremaining: 893ms\n",
      "4:\tlearn: 0.4743317\ttotal: 92.3ms\tremaining: 830ms\n",
      "5:\tlearn: 0.4541888\ttotal: 107ms\tremaining: 786ms\n",
      "6:\tlearn: 0.4410172\ttotal: 122ms\tremaining: 748ms\n",
      "7:\tlearn: 0.4288097\ttotal: 136ms\tremaining: 713ms\n",
      "8:\tlearn: 0.4181826\ttotal: 149ms\tremaining: 677ms\n",
      "9:\tlearn: 0.4067285\ttotal: 161ms\tremaining: 645ms\n",
      "10:\tlearn: 0.4003364\ttotal: 162ms\tremaining: 575ms\n",
      "11:\tlearn: 0.3925937\ttotal: 178ms\tremaining: 565ms\n",
      "12:\tlearn: 0.3857692\ttotal: 196ms\tremaining: 559ms\n",
      "13:\tlearn: 0.3814745\ttotal: 197ms\tremaining: 506ms\n",
      "14:\tlearn: 0.3756712\ttotal: 210ms\tremaining: 491ms\n",
      "15:\tlearn: 0.3696367\ttotal: 224ms\tremaining: 475ms\n",
      "16:\tlearn: 0.3632250\ttotal: 237ms\tremaining: 461ms\n",
      "17:\tlearn: 0.3568226\ttotal: 252ms\tremaining: 447ms\n",
      "18:\tlearn: 0.3508396\ttotal: 266ms\tremaining: 435ms\n",
      "19:\tlearn: 0.3462595\ttotal: 280ms\tremaining: 420ms\n",
      "20:\tlearn: 0.3405277\ttotal: 295ms\tremaining: 408ms\n",
      "21:\tlearn: 0.3359946\ttotal: 310ms\tremaining: 394ms\n",
      "22:\tlearn: 0.3319500\ttotal: 323ms\tremaining: 380ms\n",
      "23:\tlearn: 0.3271040\ttotal: 337ms\tremaining: 366ms\n",
      "24:\tlearn: 0.3234228\ttotal: 351ms\tremaining: 351ms\n",
      "25:\tlearn: 0.3189287\ttotal: 364ms\tremaining: 336ms\n",
      "26:\tlearn: 0.3144317\ttotal: 377ms\tremaining: 321ms\n",
      "27:\tlearn: 0.3107657\ttotal: 390ms\tremaining: 306ms\n",
      "28:\tlearn: 0.3079830\ttotal: 402ms\tremaining: 291ms\n",
      "29:\tlearn: 0.3039886\ttotal: 415ms\tremaining: 277ms\n",
      "30:\tlearn: 0.3009966\ttotal: 428ms\tremaining: 263ms\n",
      "31:\tlearn: 0.2957285\ttotal: 441ms\tremaining: 248ms\n",
      "32:\tlearn: 0.2906100\ttotal: 454ms\tremaining: 234ms\n",
      "33:\tlearn: 0.2854270\ttotal: 466ms\tremaining: 219ms\n",
      "34:\tlearn: 0.2820309\ttotal: 479ms\tremaining: 205ms\n",
      "35:\tlearn: 0.2788047\ttotal: 491ms\tremaining: 191ms\n",
      "36:\tlearn: 0.2777998\ttotal: 504ms\tremaining: 177ms\n",
      "37:\tlearn: 0.2741203\ttotal: 516ms\tremaining: 163ms\n",
      "38:\tlearn: 0.2719922\ttotal: 528ms\tremaining: 149ms\n",
      "39:\tlearn: 0.2689598\ttotal: 541ms\tremaining: 135ms\n",
      "40:\tlearn: 0.2650102\ttotal: 553ms\tremaining: 121ms\n",
      "41:\tlearn: 0.2637649\ttotal: 565ms\tremaining: 108ms\n",
      "42:\tlearn: 0.2626947\ttotal: 577ms\tremaining: 94ms\n",
      "43:\tlearn: 0.2617260\ttotal: 580ms\tremaining: 79.2ms\n",
      "44:\tlearn: 0.2599155\ttotal: 593ms\tremaining: 65.8ms\n",
      "45:\tlearn: 0.2582816\ttotal: 605ms\tremaining: 52.6ms\n",
      "46:\tlearn: 0.2560073\ttotal: 618ms\tremaining: 39.5ms\n",
      "47:\tlearn: 0.2531765\ttotal: 631ms\tremaining: 26.3ms\n",
      "48:\tlearn: 0.2522912\ttotal: 645ms\tremaining: 13.2ms\n",
      "49:\tlearn: 0.2511952\ttotal: 658ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x0000026DE0C64640>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'depth': [4, 5, 6, 7, 8, 9, 10],\n",
       "                         'iterations': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                        100],\n",
       "                         'learning_rate': [0.05, 0.1, 0.2, 0.25]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSmodel = CatBoostClassifier(**params)\n",
    "GridS = GridSearchCV(GSmodel, params, cv=3,verbose=2,n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 10, 'iterations': 50, 'learning_rate': 0.25}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "accuracy:  0.7982062780269058\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 7, 'min_data_in_leaf': 70, 'num_leaves': 75}\n",
    "model = LGBMClassifier(**params)\n",
    "model.fit(train_data, train_labels)\n",
    "predictions_LGBM = model.predict(test_data)\n",
    "print('accuracy: ', accuracy_score(model.predict(val_data), val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSmodel = LGBMClassifier()\n",
    "GridS = GridSearchCV(GSmodel, params, cv=3,verbose=2,n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid search (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': [1, 3, 7, 20, 31, 40, 60, 80, 127, 170, 210],\n",
    "    'max_depth': [1, 3, 5, 7, 9, 15, 20, 25, 40],\n",
    "    'min_data_in_leaf': [100, 300, 400, 700, 1000, 1300, 1500],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 693 candidates, totalling 2079 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2027 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2079 out of 2079 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [1, 3, 5, 7, 9, 15, 20, 25, 40],\n",
       "                         'min_data_in_leaf': [100, 300, 400, 700, 1000, 1300,\n",
       "                                              1500],\n",
       "                         'num_leaves': [1, 3, 7, 20, 31, 40, 60, 80, 127, 170,\n",
       "                                        210]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSmodel = LGBMClassifier()\n",
    "GridS = GridSearchCV(GSmodel, params, cv=3,verbose=2,n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_data_in_leaf': 100, 'num_leaves': 7}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search with mlflow (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "cv_accuracy: 0.8023292627770239\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "accuracy on val_data: 0.8251121076233184\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 7, 'min_data_in_leaf': 70, 'num_leaves': 75}\n",
    "mlflow.set_experiment('LGBM')\n",
    "with mlflow.start_run():\n",
    "    model=LGBMClassifier(**params)\n",
    "    #model.fit(train_data, train_labels, eval_metric = 'logloss')\n",
    "    accuracy = cross_val_score(model, train_data, train_labels, scoring='accuracy', cv = 10)\n",
    "    mlflow.log_param('params', params)\n",
    "    mlflow.log_metric('cv_accuracy', accuracy.mean())\n",
    "    print('cv_accuracy:', accuracy.mean())\n",
    "    model=LGBMClassifier(**params)\n",
    "    model.fit(train_data, train_labels)\n",
    "    print('accuracy on val_data:', accuracy_score(model.predict(val_data),val_labels))\n",
    "    mlflow.log_metric('accuracy on val_data', accuracy_score(model.predict(val_data),val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8116591928251121\n"
     ]
    }
   ],
   "source": [
    "params = {'C': 5, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0006, 'kernel': 'rbf'}\n",
    "model = SVC(**params)\n",
    "clf = make_pipeline(StandardScaler(), model)\n",
    "clf.fit(train_data, train_labels)\n",
    "predictions_SVM = clf.predict(test_data)\n",
    "print('accuracy: ', accuracy_score(clf.predict(val_data), val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearch (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'C' : np.arange(0.1,1,0.4),\n",
    "    'degree': np.arange(3,10,3),\n",
    "    'coef0': np.arange(0.001,5,2),\n",
    "    'gamma': ('auto', 'scale')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "GSmodel=SVC()\n",
    "GridS = GridSearchCV(GSmodel,params, cv=5,verbose=3, n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search with mlflow (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_accuracy: 0.822003618272275\n",
      "accuracy on val_data: 0.8385650224215246\n"
     ]
    }
   ],
   "source": [
    "params ={'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "mlflow.set_experiment('LGBM')\n",
    "with mlflow.start_run():\n",
    "    model=SVC(**params)\n",
    "    #model.fit(train_data, train_labels, eval_metric = 'logloss')\n",
    "    clf = make_pipeline(StandardScaler(), model)\n",
    "    accuracy = cross_val_score(clf, train_data, train_labels, scoring='accuracy', cv = 10)\n",
    "    mlflow.log_param('params', params)\n",
    "    mlflow.log_metric('cv_accuracy', accuracy.mean())\n",
    "    print('cv_accuracy:', accuracy.mean())\n",
    "    model=SVC(**params)\n",
    "    clf = make_pipeline(StandardScaler(), model)\n",
    "    clf.fit(train_data, train_labels)\n",
    "    print('accuracy on val_data:', accuracy_score(clf.predict(val_data),val_labels))\n",
    "    mlflow.log_metric('accuracy on val_data', accuracy_score(clf.predict(val_data),val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n",
      "accuracy:  0.7892376681614349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "params={'C': 10.0, 'penalty': 'l2'}\n",
    "model = LogisticRegression(**params)\n",
    "model.fit(train_data, train_labels)\n",
    "predictions_LogisticRegression = model.predict(test_data)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "print('accuracy: ', accuracy_score(model.predict(val_data), val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearch(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  70 | elapsed:    1.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    2.0s finished\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSmodel=LogisticRegression()\n",
    "GridS = GridSearchCV(GSmodel,params, cv=5,verbose=3, n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n",
      "accuracy:  0.8385650224215246\n"
     ]
    }
   ],
   "source": [
    "params={'n_neighbors': 13}\n",
    "model = KNeighborsClassifier(**params)\n",
    "clf = make_pipeline(StandardScaler(), model)\n",
    "clf.fit(train_data, train_labels)\n",
    "predictions_kNN = clf.predict(test_data)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "print('accuracy: ', accuracy_score(clf.predict(val_data), val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearch (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.linspace(1,32,32))\n",
    "params = {'n_neighbors': list(np.linspace(1,32,32).astype('int32'))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSmodel=KNeighborsClassifier()\n",
    "GridS = GridSearchCV(GSmodel,params, cv=5,verbose=3, n_jobs=-1)\n",
    "GridS.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 26}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = [0 for i in range(len(test_data))]\n",
    "print(len(prediction))\n",
    "for i in range(len(test_data)):\n",
    "    sum_predictions=predictions_XGB[i]+predictions_SVM[i]+predictions_kNN[i]+predictions_LogisticRegression[i]+predictions_Catboost[i]+predictions_LGBM[i]\n",
    "    if sum_predictions>3:\n",
    "        prediction[i]=1\n",
    "    else:\n",
    "        prediction[i]=0\n",
    "\n",
    "print(prediction)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_LGBM})\n",
    "output.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
