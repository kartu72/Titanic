{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title=''\n",
    "    for i in name:\n",
    "        if i==' ':\n",
    "            title=''\n",
    "        elif i=='.':\n",
    "            return title\n",
    "        else:\n",
    "            title=title+i\n",
    "    return 'Without title'\n",
    "def Cabin_null_processing(name):\n",
    "    if (type(name) is int):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def Age_null_processing1(Age):\n",
    "    return 37\n",
    "def Age_null_processing2(Age):\n",
    "    return 29\n",
    "def Age_null_processing3(Age):\n",
    "    return 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "data['Embarked']=data['Embarked'].replace(np.nan, 'S')\n",
    "test_data['Embarked']=test_data['Embarked'].replace(np.nan, 'S')\n",
    "\n",
    "#Cabin\n",
    "data['Cabin']=data['Cabin'].replace(np.nan, 0)\n",
    "data['Cabin']=data['Cabin'].map(Cabin_null_processing)\n",
    "data['Cabin']=data['Cabin'].replace(np.nan, 0)\n",
    "data['Cabin']=data['Cabin'].map(Cabin_null_processing)\n",
    "test_data['Cabin']=test_data['Cabin'].replace(np.nan, 0)\n",
    "test_data['Cabin']=test_data['Cabin'].map(Cabin_null_processing)\n",
    "test_data['Cabin']=test_data['Cabin'].replace(np.nan, 0)\n",
    "test_data['Cabin']=test_data['Cabin'].map(Cabin_null_processing)\n",
    "#data = data.drop(columns='Cabin')\n",
    "#test_data = test_data.drop(columns='Cabin')\n",
    "#Age\n",
    "for i in  range(len(data)):\n",
    "    if (pd.isna(data.loc[i, 'Age'])==True):\n",
    "        if (data.loc[i,'Pclass']==1):\n",
    "            data.loc[i,'Age'] = 37\n",
    "        elif (data.loc[i,'Pclass']==2):\n",
    "            data.loc[i,'Age'] = 29\n",
    "        elif (data.loc[i,'Pclass']==3):\n",
    "            data.loc[i,'Age'] = 27\n",
    "for i in  range(len(test_data)):\n",
    "    if (pd.isna(test_data.loc[i, 'Age'])==True):\n",
    "        if (test_data.loc[i,'Pclass']==1):\n",
    "            test_data.loc[i,'Age'] = 37\n",
    "        elif (test_data.loc[i,'Pclass']==2):\n",
    "            test_data.loc[i,'Age'] = 29\n",
    "        elif (test_data.loc[i,'Pclass']==3):\n",
    "            test_data.loc[i,'Age'] = 27            \n",
    "#Fare\n",
    "test_data['Fare']=test_data['Fare'].replace(np.nan, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sex\n",
    "data['Sex']=LabelEncoder().fit_transform(data.Sex)\n",
    "test_data['Sex']=LabelEncoder().fit_transform(test_data.Sex)\n",
    "\n",
    "#Ticket\n",
    "data=data.drop(columns=['Ticket'])\n",
    "test_data=test_data.drop(columns=['Ticket'])\n",
    "#data['Ticket']=LabelEncoder().fit_transform(data.Ticket)\n",
    "#data1['Ticket']=LabelEncoder().fit_transform(data1.Ticket)\n",
    "\n",
    "#New feature 'Title' & drop 'Name'\n",
    "data['Title']=data['Name'].map(get_title)\n",
    "data=data.drop(columns=['Name'])\n",
    "test_data['Title']=test_data['Name'].map(get_title)\n",
    "test_data=test_data.drop(columns=['Name'])\n",
    "\n",
    "#Embarked\n",
    "data['Embarked']=LabelEncoder().fit_transform(data.Embarked)\n",
    "test_data['Embarked']=LabelEncoder().fit_transform(test_data.Embarked)\n",
    "\n",
    "#PassengerId\n",
    "ids = test_data['PassengerId']\n",
    "#data=data.drop(columns='PassengerId')\n",
    "#test_data=test_data.drop(columns='PassengerId')\n",
    "\n",
    "#Title\n",
    "data['Title']=LabelEncoder().fit_transform(data.Title)\n",
    "test_data['Title']=LabelEncoder().fit_transform(test_data.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Survived']\n",
    "data = data.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked  \\\n",
       "0          892       3    1  34.5      0      0   7.8292      0         1   \n",
       "1          893       3    0  47.0      1      0   7.0000      0         2   \n",
       "2          894       2    1  62.0      0      0   9.6875      0         1   \n",
       "3          895       3    1  27.0      0      0   8.6625      0         2   \n",
       "4          896       3    0  22.0      1      1  12.2875      0         2   \n",
       "\n",
       "   Title  \n",
       "0      5  \n",
       "1      6  \n",
       "2      5  \n",
       "3      5  \n",
       "4      6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sex\n",
    "data=pd.get_dummies(data, prefix = ['Sex'], columns = ['Sex'])\n",
    "test_data=pd.get_dummies(test_data, prefix = ['Sex'], columns = ['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticket\n",
    "data=data.drop(columns=['Ticket'])\n",
    "test_data=test_data.drop(columns=['Ticket'])\n",
    "#data['Ticket']=LabelEncoder().fit_transform(data.Ticket)\n",
    "#data1['Ticket']=LabelEncoder().fit_transform(data1.Ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New feature 'Title' & drop 'Name'\n",
    "data['Title']=data['Name'].map(get_title)\n",
    "data=data.drop(columns=['Name'])\n",
    "test_data['Title']=test_data['Name'].map(get_title)\n",
    "test_data=test_data.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "data=pd.get_dummies(data, prefix = ['Emb'], columns = ['Embarked'])\n",
    "test_data=pd.get_dummies(test_data, prefix = ['Emb'], columns = ['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_data['PassengerId']\n",
    "#PassengerId\n",
    "#data=data.drop(columns='PassengerId')\n",
    "#data1=data1.drop(columns='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title\n",
    "data['Title']=LabelEncoder().fit_transform(data.Title)\n",
    "test_data['Title']=LabelEncoder().fit_transform(test_data.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Survived']\n",
    "data = data.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "D:\\anaconda\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Sex\n",
    "data['Sex']=TargetEncoder().fit_transform(data.Sex, data['Survived'])\n",
    "test_data['Sex']=TargetEncoder().fit_transform(test_data.Sex, data['Survived'][:418])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticket\n",
    "data=data.drop(columns=['Ticket'])\n",
    "test_data=test_data.drop(columns=['Ticket'])\n",
    "#data['Ticket']=LabelEncoder().fit_transform(data.Ticket)\n",
    "#data1['Ticket']=LabelEncoder().fit_transform(data1.Ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New feature 'Title' & drop 'Name'\n",
    "data['Title']=data['Name'].map(get_title)\n",
    "data=data.drop(columns=['Name'])\n",
    "test_data['Title']=test_data['Name'].map(get_title)\n",
    "test_data=test_data.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "D:\\anaconda\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Embarked\n",
    "data['Embarked']=TargetEncoder().fit_transform(data.Embarked, data['Survived'])\n",
    "test_data['Embarked']=TargetEncoder().fit_transform(test_data.Embarked, data['Survived'][:418])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PassengerId\n",
    "#data=data.drop(columns='PassengerId')\n",
    "#data1=data1.drop(columns='PassengerId')\n",
    "ids=test_data.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "D:\\anaconda\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Title\n",
    "data['Title']=TargetEncoder().fit_transform(data.Title, data['Survived'])\n",
    "test_data['Title']=TargetEncoder().fit_transform(test_data.Title, data['Survived'][:418])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Survived']\n",
    "data = data.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training (with different encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap': False,\n",
    " 'max_depth': 70,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 600}\n",
    "model = RandomForestClassifier(**params, random_state=42)\n",
    "#print('cv accuracy: ', cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "model.fit(data, labels)\n",
    "predictions_RF = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:17:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "params={'colsample_bytree': 0.8,\n",
    " 'gamma': 0,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 0.5,\n",
    " 'n_estimators': 50,\n",
    " 'reg_lambda': 0.1,\n",
    " 'subsample': 0.8}\n",
    "model = XGBClassifier(**params , random_state=42)\n",
    "#print('cv accuracy: ', cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "model.fit(data, labels)\n",
    "predictions_XGB = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6180833\ttotal: 52.3ms\tremaining: 995ms\n",
      "1:\tlearn: 0.5676798\ttotal: 52.9ms\tremaining: 476ms\n",
      "2:\tlearn: 0.5259805\ttotal: 53.6ms\tremaining: 304ms\n",
      "3:\tlearn: 0.5064744\ttotal: 53.9ms\tremaining: 216ms\n",
      "4:\tlearn: 0.4851243\ttotal: 54.4ms\tremaining: 163ms\n",
      "5:\tlearn: 0.4670790\ttotal: 55.5ms\tremaining: 130ms\n",
      "6:\tlearn: 0.4509785\ttotal: 56.5ms\tremaining: 105ms\n",
      "7:\tlearn: 0.4377828\ttotal: 57.5ms\tremaining: 86.2ms\n",
      "8:\tlearn: 0.4259909\ttotal: 58.5ms\tremaining: 71.5ms\n",
      "9:\tlearn: 0.4157459\ttotal: 59.5ms\tremaining: 59.5ms\n",
      "10:\tlearn: 0.4116442\ttotal: 60.5ms\tremaining: 49.5ms\n",
      "11:\tlearn: 0.4051289\ttotal: 61.5ms\tremaining: 41ms\n",
      "12:\tlearn: 0.4001645\ttotal: 62.4ms\tremaining: 33.6ms\n",
      "13:\tlearn: 0.3950606\ttotal: 63.4ms\tremaining: 27.2ms\n",
      "14:\tlearn: 0.3907065\ttotal: 64.4ms\tremaining: 21.5ms\n",
      "15:\tlearn: 0.3892237\ttotal: 65.3ms\tremaining: 16.3ms\n",
      "16:\tlearn: 0.3849990\ttotal: 66.3ms\tremaining: 11.7ms\n",
      "17:\tlearn: 0.3825250\ttotal: 67.2ms\tremaining: 7.47ms\n",
      "18:\tlearn: 0.3793567\ttotal: 68.2ms\tremaining: 3.59ms\n",
      "19:\tlearn: 0.3774655\ttotal: 69.2ms\tremaining: 0us\n",
      "0:\tlearn: 0.6241736\ttotal: 1.17ms\tremaining: 22.2ms\n",
      "1:\tlearn: 0.5720176\ttotal: 1.71ms\tremaining: 15.4ms\n",
      "2:\tlearn: 0.5314008\ttotal: 2.4ms\tremaining: 13.6ms\n",
      "3:\tlearn: 0.5114767\ttotal: 2.74ms\tremaining: 11ms\n",
      "4:\tlearn: 0.4941895\ttotal: 3.25ms\tremaining: 9.74ms\n",
      "5:\tlearn: 0.4742547\ttotal: 4.19ms\tremaining: 9.79ms\n",
      "6:\tlearn: 0.4581090\ttotal: 5.16ms\tremaining: 9.59ms\n",
      "7:\tlearn: 0.4453684\ttotal: 6.16ms\tremaining: 9.24ms\n",
      "8:\tlearn: 0.4335759\ttotal: 7.11ms\tremaining: 8.69ms\n",
      "9:\tlearn: 0.4272142\ttotal: 7.62ms\tremaining: 7.62ms\n",
      "10:\tlearn: 0.4206275\ttotal: 8.54ms\tremaining: 6.98ms\n",
      "11:\tlearn: 0.4151331\ttotal: 9.46ms\tremaining: 6.31ms\n",
      "12:\tlearn: 0.4110151\ttotal: 10.4ms\tremaining: 5.58ms\n",
      "13:\tlearn: 0.4067022\ttotal: 11.3ms\tremaining: 4.83ms\n",
      "14:\tlearn: 0.4014407\ttotal: 12.2ms\tremaining: 4.07ms\n",
      "15:\tlearn: 0.3993931\ttotal: 13.1ms\tremaining: 3.29ms\n",
      "16:\tlearn: 0.3947453\ttotal: 14.2ms\tremaining: 2.5ms\n",
      "17:\tlearn: 0.3919909\ttotal: 15.1ms\tremaining: 1.68ms\n",
      "18:\tlearn: 0.3877784\ttotal: 16.1ms\tremaining: 846us\n",
      "19:\tlearn: 0.3837901\ttotal: 17ms\tremaining: 0us\n",
      "0:\tlearn: 0.6206328\ttotal: 1.37ms\tremaining: 26.1ms\n",
      "1:\tlearn: 0.5673313\ttotal: 1.94ms\tremaining: 17.5ms\n",
      "2:\tlearn: 0.5234104\ttotal: 2.63ms\tremaining: 14.9ms\n",
      "3:\tlearn: 0.5029029\ttotal: 2.95ms\tremaining: 11.8ms\n",
      "4:\tlearn: 0.4843032\ttotal: 3.47ms\tremaining: 10.4ms\n",
      "5:\tlearn: 0.4639987\ttotal: 4.65ms\tremaining: 10.9ms\n",
      "6:\tlearn: 0.4478560\ttotal: 5.68ms\tremaining: 10.6ms\n",
      "7:\tlearn: 0.4328928\ttotal: 6.66ms\tremaining: 9.99ms\n",
      "8:\tlearn: 0.4240846\ttotal: 7.17ms\tremaining: 8.76ms\n",
      "9:\tlearn: 0.4149673\ttotal: 8.11ms\tremaining: 8.11ms\n",
      "10:\tlearn: 0.4057029\ttotal: 9.05ms\tremaining: 7.4ms\n",
      "11:\tlearn: 0.3972041\ttotal: 9.97ms\tremaining: 6.65ms\n",
      "12:\tlearn: 0.3920633\ttotal: 10.9ms\tremaining: 5.85ms\n",
      "13:\tlearn: 0.3883807\ttotal: 11.8ms\tremaining: 5.05ms\n",
      "14:\tlearn: 0.3833295\ttotal: 12.7ms\tremaining: 4.25ms\n",
      "15:\tlearn: 0.3803894\ttotal: 13.7ms\tremaining: 3.42ms\n",
      "16:\tlearn: 0.3758010\ttotal: 14.6ms\tremaining: 2.58ms\n",
      "17:\tlearn: 0.3725543\ttotal: 15.5ms\tremaining: 1.73ms\n",
      "18:\tlearn: 0.3676453\ttotal: 16.5ms\tremaining: 867us\n",
      "19:\tlearn: 0.3652144\ttotal: 17.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6236186\ttotal: 2.17ms\tremaining: 41.2ms\n",
      "1:\tlearn: 0.5727527\ttotal: 2.76ms\tremaining: 24.8ms\n",
      "2:\tlearn: 0.5326197\ttotal: 3.49ms\tremaining: 19.8ms\n",
      "3:\tlearn: 0.5134884\ttotal: 3.84ms\tremaining: 15.4ms\n",
      "4:\tlearn: 0.4966858\ttotal: 4.38ms\tremaining: 13.1ms\n",
      "5:\tlearn: 0.4775092\ttotal: 5.36ms\tremaining: 12.5ms\n",
      "6:\tlearn: 0.4623333\ttotal: 6.36ms\tremaining: 11.8ms\n",
      "7:\tlearn: 0.4493524\ttotal: 7.37ms\tremaining: 11.1ms\n",
      "8:\tlearn: 0.4379444\ttotal: 8.35ms\tremaining: 10.2ms\n",
      "9:\tlearn: 0.4273341\ttotal: 9.33ms\tremaining: 9.33ms\n",
      "10:\tlearn: 0.4232152\ttotal: 10.3ms\tremaining: 8.44ms\n",
      "11:\tlearn: 0.4175457\ttotal: 11.3ms\tremaining: 7.52ms\n",
      "12:\tlearn: 0.4119685\ttotal: 12.3ms\tremaining: 6.6ms\n",
      "13:\tlearn: 0.4077329\ttotal: 13.2ms\tremaining: 5.66ms\n",
      "14:\tlearn: 0.4036811\ttotal: 13.9ms\tremaining: 4.63ms\n",
      "15:\tlearn: 0.3994738\ttotal: 14.8ms\tremaining: 3.71ms\n",
      "16:\tlearn: 0.3950798\ttotal: 15.8ms\tremaining: 2.79ms\n",
      "17:\tlearn: 0.3909020\ttotal: 16.8ms\tremaining: 1.87ms\n",
      "18:\tlearn: 0.3881777\ttotal: 17.8ms\tremaining: 934us\n",
      "19:\tlearn: 0.3861109\ttotal: 18.3ms\tremaining: 0us\n",
      "0:\tlearn: 0.6231762\ttotal: 1.23ms\tremaining: 23.4ms\n",
      "1:\tlearn: 0.5728783\ttotal: 2ms\tremaining: 18ms\n",
      "2:\tlearn: 0.5319858\ttotal: 2.72ms\tremaining: 15.4ms\n",
      "3:\tlearn: 0.5122142\ttotal: 3.17ms\tremaining: 12.7ms\n",
      "4:\tlearn: 0.4944398\ttotal: 3.88ms\tremaining: 11.6ms\n",
      "5:\tlearn: 0.4755860\ttotal: 4.97ms\tremaining: 11.6ms\n",
      "6:\tlearn: 0.4602202\ttotal: 5.99ms\tremaining: 11.1ms\n",
      "7:\tlearn: 0.4477782\ttotal: 7.13ms\tremaining: 10.7ms\n",
      "8:\tlearn: 0.4350777\ttotal: 8.32ms\tremaining: 10.2ms\n",
      "9:\tlearn: 0.4287465\ttotal: 8.86ms\tremaining: 8.86ms\n",
      "10:\tlearn: 0.4200091\ttotal: 9.82ms\tremaining: 8.03ms\n",
      "11:\tlearn: 0.4150834\ttotal: 10.8ms\tremaining: 7.18ms\n",
      "12:\tlearn: 0.4094260\ttotal: 11.7ms\tremaining: 6.3ms\n",
      "13:\tlearn: 0.4057329\ttotal: 12.6ms\tremaining: 5.41ms\n",
      "14:\tlearn: 0.4032604\ttotal: 13.2ms\tremaining: 4.39ms\n",
      "15:\tlearn: 0.3994442\ttotal: 14.2ms\tremaining: 3.54ms\n",
      "16:\tlearn: 0.3958976\ttotal: 15.6ms\tremaining: 2.75ms\n",
      "17:\tlearn: 0.3926830\ttotal: 16.7ms\tremaining: 1.85ms\n",
      "18:\tlearn: 0.3909973\ttotal: 17.7ms\tremaining: 932us\n",
      "19:\tlearn: 0.3869169\ttotal: 18.8ms\tremaining: 0us\n",
      "0:\tlearn: 0.6203668\ttotal: 1.25ms\tremaining: 23.8ms\n",
      "1:\tlearn: 0.5693526\ttotal: 1.86ms\tremaining: 16.8ms\n",
      "2:\tlearn: 0.5284166\ttotal: 2.56ms\tremaining: 14.5ms\n",
      "3:\tlearn: 0.5081853\ttotal: 2.9ms\tremaining: 11.6ms\n",
      "4:\tlearn: 0.4901916\ttotal: 3.42ms\tremaining: 10.3ms\n",
      "5:\tlearn: 0.4704637\ttotal: 4.37ms\tremaining: 10.2ms\n",
      "6:\tlearn: 0.4577846\ttotal: 4.79ms\tremaining: 8.9ms\n",
      "7:\tlearn: 0.4429451\ttotal: 5.83ms\tremaining: 8.74ms\n",
      "8:\tlearn: 0.4317380\ttotal: 6.87ms\tremaining: 8.4ms\n",
      "9:\tlearn: 0.4226178\ttotal: 7.81ms\tremaining: 7.81ms\n",
      "10:\tlearn: 0.4156236\ttotal: 8.76ms\tremaining: 7.17ms\n",
      "11:\tlearn: 0.4107416\ttotal: 9.69ms\tremaining: 6.46ms\n",
      "12:\tlearn: 0.4044717\ttotal: 10.7ms\tremaining: 5.76ms\n",
      "13:\tlearn: 0.3993853\ttotal: 11.7ms\tremaining: 5ms\n",
      "14:\tlearn: 0.3961113\ttotal: 12.7ms\tremaining: 4.22ms\n",
      "15:\tlearn: 0.3930454\ttotal: 13.6ms\tremaining: 3.41ms\n",
      "16:\tlearn: 0.3904299\ttotal: 14.6ms\tremaining: 2.58ms\n",
      "17:\tlearn: 0.3870978\ttotal: 15.6ms\tremaining: 1.73ms\n",
      "18:\tlearn: 0.3834578\ttotal: 16.5ms\tremaining: 867us\n",
      "19:\tlearn: 0.3814151\ttotal: 17.2ms\tremaining: 0us\n",
      "0:\tlearn: 0.6230623\ttotal: 1.25ms\tremaining: 23.7ms\n",
      "1:\tlearn: 0.5718397\ttotal: 1.82ms\tremaining: 16.4ms\n",
      "2:\tlearn: 0.5310502\ttotal: 2.51ms\tremaining: 14.2ms\n",
      "3:\tlearn: 0.5105472\ttotal: 2.87ms\tremaining: 11.5ms\n",
      "4:\tlearn: 0.4897718\ttotal: 3.38ms\tremaining: 10.2ms\n",
      "5:\tlearn: 0.4715286\ttotal: 4.41ms\tremaining: 10.3ms\n",
      "6:\tlearn: 0.4559074\ttotal: 5.46ms\tremaining: 10.2ms\n",
      "7:\tlearn: 0.4424850\ttotal: 6.44ms\tremaining: 9.66ms\n",
      "8:\tlearn: 0.4306030\ttotal: 7.4ms\tremaining: 9.05ms\n",
      "9:\tlearn: 0.4212242\ttotal: 8.37ms\tremaining: 8.37ms\n",
      "10:\tlearn: 0.4140983\ttotal: 9.3ms\tremaining: 7.61ms\n",
      "11:\tlearn: 0.4090334\ttotal: 10.3ms\tremaining: 6.83ms\n",
      "12:\tlearn: 0.4042685\ttotal: 11.2ms\tremaining: 6.02ms\n",
      "13:\tlearn: 0.4008489\ttotal: 12.1ms\tremaining: 5.19ms\n",
      "14:\tlearn: 0.3967750\ttotal: 13ms\tremaining: 4.35ms\n",
      "15:\tlearn: 0.3949171\ttotal: 14ms\tremaining: 3.49ms\n",
      "16:\tlearn: 0.3907353\ttotal: 14.9ms\tremaining: 2.63ms\n",
      "17:\tlearn: 0.3879605\ttotal: 15.9ms\tremaining: 1.76ms\n",
      "18:\tlearn: 0.3849657\ttotal: 16.8ms\tremaining: 885us\n",
      "19:\tlearn: 0.3822655\ttotal: 17.8ms\tremaining: 0us\n",
      "0:\tlearn: 0.6222806\ttotal: 1.38ms\tremaining: 26.2ms\n",
      "1:\tlearn: 0.5691847\ttotal: 1.82ms\tremaining: 16.4ms\n",
      "2:\tlearn: 0.5325151\ttotal: 2.26ms\tremaining: 12.8ms\n",
      "3:\tlearn: 0.5026834\ttotal: 3.23ms\tremaining: 12.9ms\n",
      "4:\tlearn: 0.4843264\ttotal: 4.23ms\tremaining: 12.7ms\n",
      "5:\tlearn: 0.4656980\ttotal: 4.95ms\tremaining: 11.6ms\n",
      "6:\tlearn: 0.4504385\ttotal: 5.94ms\tremaining: 11ms\n",
      "7:\tlearn: 0.4388573\ttotal: 6.92ms\tremaining: 10.4ms\n",
      "8:\tlearn: 0.4346504\ttotal: 7.25ms\tremaining: 8.86ms\n",
      "9:\tlearn: 0.4256760\ttotal: 8.23ms\tremaining: 8.23ms\n",
      "10:\tlearn: 0.4194679\ttotal: 9.17ms\tremaining: 7.5ms\n",
      "11:\tlearn: 0.4123059\ttotal: 10.2ms\tremaining: 6.77ms\n",
      "12:\tlearn: 0.4066890\ttotal: 11.1ms\tremaining: 5.97ms\n",
      "13:\tlearn: 0.4031138\ttotal: 12ms\tremaining: 5.16ms\n",
      "14:\tlearn: 0.3983737\ttotal: 13ms\tremaining: 4.34ms\n",
      "15:\tlearn: 0.3969856\ttotal: 14ms\tremaining: 3.49ms\n",
      "16:\tlearn: 0.3922939\ttotal: 14.9ms\tremaining: 2.64ms\n",
      "17:\tlearn: 0.3916117\ttotal: 15.4ms\tremaining: 1.71ms\n",
      "18:\tlearn: 0.3875830\ttotal: 16.3ms\tremaining: 858us\n",
      "19:\tlearn: 0.3842166\ttotal: 17.3ms\tremaining: 0us\n",
      "0:\tlearn: 0.6212301\ttotal: 1.22ms\tremaining: 23.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\tlearn: 0.5717697\ttotal: 1.87ms\tremaining: 16.8ms\n",
      "2:\tlearn: 0.5374666\ttotal: 2.31ms\tremaining: 13.1ms\n",
      "3:\tlearn: 0.5081590\ttotal: 3.61ms\tremaining: 14.4ms\n",
      "4:\tlearn: 0.4903880\ttotal: 4.58ms\tremaining: 13.8ms\n",
      "5:\tlearn: 0.4743879\ttotal: 5.48ms\tremaining: 12.8ms\n",
      "6:\tlearn: 0.4592509\ttotal: 6.53ms\tremaining: 12.1ms\n",
      "7:\tlearn: 0.4463197\ttotal: 7.53ms\tremaining: 11.3ms\n",
      "8:\tlearn: 0.4425471\ttotal: 7.96ms\tremaining: 9.72ms\n",
      "9:\tlearn: 0.4353579\ttotal: 9.13ms\tremaining: 9.13ms\n",
      "10:\tlearn: 0.4286882\ttotal: 10.2ms\tremaining: 8.33ms\n",
      "11:\tlearn: 0.4233025\ttotal: 11.2ms\tremaining: 7.46ms\n",
      "12:\tlearn: 0.4188460\ttotal: 12.2ms\tremaining: 6.56ms\n",
      "13:\tlearn: 0.4146156\ttotal: 13.2ms\tremaining: 5.65ms\n",
      "14:\tlearn: 0.4090035\ttotal: 14.2ms\tremaining: 4.75ms\n",
      "15:\tlearn: 0.4057544\ttotal: 15.4ms\tremaining: 3.86ms\n",
      "16:\tlearn: 0.4012713\ttotal: 16.8ms\tremaining: 2.97ms\n",
      "17:\tlearn: 0.3986761\ttotal: 18.4ms\tremaining: 2.04ms\n",
      "18:\tlearn: 0.3947251\ttotal: 19.4ms\tremaining: 1.02ms\n",
      "19:\tlearn: 0.3910862\ttotal: 20.4ms\tremaining: 0us\n",
      "0:\tlearn: 0.6177385\ttotal: 1.19ms\tremaining: 22.6ms\n",
      "1:\tlearn: 0.5679654\ttotal: 1.65ms\tremaining: 14.8ms\n",
      "2:\tlearn: 0.5334026\ttotal: 2.06ms\tremaining: 11.7ms\n",
      "3:\tlearn: 0.5051520\ttotal: 3.02ms\tremaining: 12.1ms\n",
      "4:\tlearn: 0.4842557\ttotal: 3.95ms\tremaining: 11.8ms\n",
      "5:\tlearn: 0.4674540\ttotal: 4.96ms\tremaining: 11.6ms\n",
      "6:\tlearn: 0.4567786\ttotal: 5.89ms\tremaining: 10.9ms\n",
      "7:\tlearn: 0.4461361\ttotal: 6.82ms\tremaining: 10.2ms\n",
      "8:\tlearn: 0.4361362\ttotal: 8.03ms\tremaining: 9.82ms\n",
      "9:\tlearn: 0.4276018\ttotal: 9.05ms\tremaining: 9.05ms\n",
      "10:\tlearn: 0.4241579\ttotal: 9.96ms\tremaining: 8.15ms\n",
      "11:\tlearn: 0.4192419\ttotal: 10.9ms\tremaining: 7.25ms\n",
      "12:\tlearn: 0.4141301\ttotal: 11.8ms\tremaining: 6.35ms\n",
      "13:\tlearn: 0.4113409\ttotal: 12.7ms\tremaining: 5.45ms\n",
      "14:\tlearn: 0.4073226\ttotal: 13.6ms\tremaining: 4.55ms\n",
      "15:\tlearn: 0.4021991\ttotal: 14.6ms\tremaining: 3.64ms\n",
      "16:\tlearn: 0.3989834\ttotal: 15.5ms\tremaining: 2.73ms\n",
      "17:\tlearn: 0.3954435\ttotal: 16.4ms\tremaining: 1.83ms\n",
      "18:\tlearn: 0.3929297\ttotal: 17.4ms\tremaining: 914us\n",
      "19:\tlearn: 0.3918260\ttotal: 18.3ms\tremaining: 0us\n",
      "0:\tlearn: 0.6224073\ttotal: 1.41ms\tremaining: 26.7ms\n",
      "1:\tlearn: 0.5702784\ttotal: 1.92ms\tremaining: 17.3ms\n",
      "2:\tlearn: 0.5343035\ttotal: 2.44ms\tremaining: 13.9ms\n",
      "3:\tlearn: 0.5033783\ttotal: 3.44ms\tremaining: 13.8ms\n",
      "4:\tlearn: 0.4849119\ttotal: 4.44ms\tremaining: 13.3ms\n",
      "5:\tlearn: 0.4676256\ttotal: 5.2ms\tremaining: 12.1ms\n",
      "6:\tlearn: 0.4523361\ttotal: 6.22ms\tremaining: 11.6ms\n",
      "7:\tlearn: 0.4403388\ttotal: 7.21ms\tremaining: 10.8ms\n",
      "8:\tlearn: 0.4364014\ttotal: 7.58ms\tremaining: 9.26ms\n",
      "9:\tlearn: 0.4279121\ttotal: 8.58ms\tremaining: 8.58ms\n",
      "10:\tlearn: 0.4203191\ttotal: 9.58ms\tremaining: 7.84ms\n",
      "11:\tlearn: 0.4131875\ttotal: 10.6ms\tremaining: 7.04ms\n",
      "12:\tlearn: 0.4094420\ttotal: 11.1ms\tremaining: 5.98ms\n",
      "13:\tlearn: 0.4050291\ttotal: 12.1ms\tremaining: 5.19ms\n",
      "14:\tlearn: 0.4004825\ttotal: 13.1ms\tremaining: 4.36ms\n",
      "15:\tlearn: 0.3966278\ttotal: 14.1ms\tremaining: 3.52ms\n",
      "16:\tlearn: 0.3921945\ttotal: 15.1ms\tremaining: 2.66ms\n",
      "17:\tlearn: 0.3889852\ttotal: 16ms\tremaining: 1.78ms\n",
      "18:\tlearn: 0.3859411\ttotal: 17ms\tremaining: 896us\n",
      "19:\tlearn: 0.3820982\ttotal: 18ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "params ={'depth': 6, 'iterations': 20, 'learning_rate': 0.2}\n",
    "model = CatBoostClassifier(**params, random_state=42)\n",
    "#print('cv accuracy: ', cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "model.fit(data, labels)\n",
    "predictions_Catboost = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 3, 'min_data_in_leaf': 100, 'num_leaves': 3}\n",
    "model = LGBMClassifier(**params,  random_state=42)\n",
    "#print('cv accuracy: ', cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(model, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "model.fit(data, labels)\n",
    "predictions_LGBM = model.predict(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': 5, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0006, 'kernel': 'rbf'}\n",
    "model = SVC(**params,  random_state=42)\n",
    "clf = make_pipeline(StandardScaler(), model)\n",
    "#print('cv accuracy: ', cross_val_score(clf, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(clf, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "clf.fit(data, labels)\n",
    "predictions_SVM = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'C': 1.0, 'penalty': 'l2'}\n",
    "model = LogisticRegression(**params)\n",
    "clf = make_pipeline(StandardScaler(), model)\n",
    "#print('cv accuracy: ', cross_val_score(clf, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(clf, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "clf.fit(data, labels)\n",
    "predictions_LogisticRegression = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'n_neighbors': 13}\n",
    "model = KNeighborsClassifier(**params)\n",
    "clf = make_pipeline(StandardScaler(), model)\n",
    "#print('cv accuracy: ', cross_val_score(clf, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "cv_acc1.append(cross_val_score(clf, data, labels, scoring='accuracy', cv = 10).mean())\n",
    "clf.fit(data, labels)\n",
    "\n",
    "predictions_kNN = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = [0 for i in range(len(test_data))]\n",
    "print(len(prediction))\n",
    "for i in range(len(test_data)):\n",
    "    sum_predictions=predictions_XGB[i]+predictions_SVM[i]+predictions_kNN[i]+predictions_LogisticRegression[i]+predictions_Catboost[i]+predictions_LGBM[i]\n",
    "    if sum_predictions>3:\n",
    "        prediction[i]=1\n",
    "    else:\n",
    "        prediction[i]=0\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': ids, 'Survived': prediction})\n",
    "output.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc1=([0.82493134, 0.81033708, 0.81705368, 0.79575531, 0.78672909,\n",
    "       0.79575531, 0.81707865])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc2 = [0.8249313358302123, 0.8126092384519351, 0.8237952559300874, 0.7957553058676654, 0.786729088639201,\n",
    " 0.7946317103620475, 0.8170911360799001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc3 = [0.826067415730337, 0.8170786516853932, 0.8114856429463172, 0.7900998751560551, 0.8193133583021224,\n",
    " 0.8294132334581772, 0.8361548064918851]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['RF', 'XGB', 'CatBoost', 'LGBM', 'SVM', 'Logistic Regression', 'kNN']\n",
    "zeros = [0 for i in range(7)]\n",
    "df = pd.DataFrame({'model': models, 'label': cv_acc1, 'one_hot': cv_acc2, 'target':cv_acc3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "      <th>one_hot</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.824931</td>\n",
       "      <td>0.824931</td>\n",
       "      <td>0.826067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.810337</td>\n",
       "      <td>0.812609</td>\n",
       "      <td>0.817079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.817054</td>\n",
       "      <td>0.823795</td>\n",
       "      <td>0.811486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.795755</td>\n",
       "      <td>0.795755</td>\n",
       "      <td>0.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.786729</td>\n",
       "      <td>0.786729</td>\n",
       "      <td>0.819313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.795755</td>\n",
       "      <td>0.794632</td>\n",
       "      <td>0.829413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.817079</td>\n",
       "      <td>0.817091</td>\n",
       "      <td>0.836155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model     label   one_hot    target\n",
       "0                   RF  0.824931  0.824931  0.826067\n",
       "1                  XGB  0.810337  0.812609  0.817079\n",
       "2             CatBoost  0.817054  0.823795  0.811486\n",
       "3                 LGBM  0.795755  0.795755  0.790100\n",
       "4                  SVM  0.786729  0.786729  0.819313\n",
       "5  Logistic Regression  0.795755  0.794632  0.829413\n",
       "6                  kNN  0.817079  0.817091  0.836155"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
